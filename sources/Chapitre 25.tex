\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{setspace}
\usepackage{ulem}
\usepackage{stmaryrd}
\usepackage{amsthm}
\usepackage{dsfont}
\usepackage{mathpazo}


\onehalfspacing

\theoremstyle{definition}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{theorem}[proposition]{Théorème}
\newtheorem{corollaire}[proposition]{Corollaire}
\newtheorem{lemme}[proposition]{Lemme}
\newtheorem{definition}[proposition]{Définition}

\DeclareMathOperator{\supp}{Supp}
\DeclareMathOperator{\mat}{Mat}
\DeclareMathOperator{\com}{com}

\begin{document}
\renewcommand{\labelitemi}{$*$}
\begin{center}
{\Large \textbf{Chapitre 25: Déterminants}}
\end{center}

\section{Groupe symétrique}
\subsection{Généralités}
\begin{definition}
On appelle \uline{groupe symétrique sur $n \geq 1$ "lettres"} le groupe $\gamma(n)$ des bijections $\llbracket 1, n \rrbracket \to \llbracket 1, n \rrbracket$
\end{definition}
\begin{definition}
Soit $\sigma \in \gamma(n)$
\begin{itemize}
\item Un élément $i \in \llbracket 1, n \rrbracket$ est un \uline{point fixe} de $\sigma$ si $\sigma(i) = i$
\item Le \uline{support} de $\sigma$ est $\supp(\sigma) = \left\{ i \in \llbracket 1, n \rrbracket \mid \sigma(i) \neq i \right\}$
\end{itemize}
\end{definition}
\begin{definition}
\hfill
\begin{itemize}
\item Une transposition est une permutation $\tau \in \gamma(n)$ dont le support est une paire $\{ i, j \}$ \\
(et qui échange $i$ et $j$). On la note $\tau = (i \, j)$ \\
On a $(i \, j) = (j \, i)$
\item Plus généralement, si $i_1, ...\, , i_r \in \llbracket 1, n \rrbracket$ sont tous différents, on note $(i_1 \, i_2 \, i_3 \, ... \, i_r)$ \\
la permutation $\sigma$ telle que
\[\begin{cases}
\forall k \in \llbracket 1, r - 1 \rrbracket,\, \sigma(i_k) = i_{k + 1} \\
\sigma(i_r) = i_1, \text{ et } \forall j \notin \{ i_1, ...\, , i_r\},\, \sigma(j) \neq j
\end{cases}\]
Une telle permutation est appelée un $r$-cycle.
\end{itemize}
\end{definition}
\begin{theorem}
Le groupe $\gamma(n)$ est engendré par les transpositions.
\end{theorem}

\subsection{Décomposition en cycles disjoints}
\begin{theorem}
Soit $\sigma \in \gamma(n)$ \\
Il existe un entier $r \geq 0$ et des cycles $\gamma_1, ...\, \gamma_r$ à supports disjoints tels que $\sigma = \gamma_r \circ ... \circ \gamma_1$ \\
En outre, cette décomposition est unique à l'ordre des facteurs près.
\end{theorem}

\subsection{Signature d'une permutation}
\begin{theorem}
Il existe un unique morphisme de groupes $\varepsilon: (\gamma(n), \circ) \to (\{ \pm 1 \}, \times)$ tel que, pour toute \uline{transposition} $\tau \in \gamma(n)$, $\varepsilon(\tau) = -1$ \\
(ce morphisme s'appelle la \uline{signature})
\end{theorem}
\begin{lemme}
\[\varepsilon(\sigma) = \prod_{\{i, j\} \in \mathcal{P}_2(\llbracket 1, n \rrbracket)} \frac{\sigma(j) - \sigma(i)}{j - i}\]
\end{lemme}
\begin{proposition}
Soit $r \in \llbracket 2, n \rrbracket$ et $\sigma \in \gamma(n)$ un $r$-cycle. \\
Alors $\varepsilon(\sigma) = (-1)^{r + 1}$
\end{proposition}
\begin{definition}
On appelle \uline{groupe alterné} $a(n)$ le noyau de la signature $a(n) = \left\{ \sigma \in \gamma(n) \mid \varepsilon(\sigma) = 1 \right\}$
\end{definition}

\pagebreak

\section{Déterminant}
Soit $K$ un corps.
\subsection{Déterminant d'une matrice carrée}
\begin{definition}
Soit $A \in M_n(K)$ \\
On définit son \uline{déterminant}:
\[ \det(A) = \sum_{\sigma \in \gamma(n)} \varepsilon(\sigma) \prod_{j = 1}^n [A]_{\sigma(j) \, j}\]
On note aussi
\[ \det A = \begin{vmatrix}
[A]_{1, 1} & \cdots & [A]_{1, n} \\
\vdots & & \vdots \\
[A]_{n, 1} & \cdots & [A]_{n ,n}
\end{vmatrix}\]
\end{definition}

\subsection{Formes $n$-linéaires alternés}
\begin{definition}
Une \uline{forme $n$-linéaire} sur un espace vectoriel $E$ est une application $f: E^n \to K$ linéaire en chacune de ses variables, càd telle que pour tous $x_1, ...\,, x_n \in E$ et $i \in \llbracket 1, n \rrbracket$ l'application 
\[\begin{cases}
E \to K \\
y \mapsto f(x_1, ...\,, x_{i - 1}, y, x_{i + 1}, ...\,, x_n)
\end{cases}\]
soit linéaire.
\end{definition}
\begin{definition}
Une forme \uline{$n$-linéaire} $f: E^n \to K$ est dite alternée si $f(x_1, ...\,, x_n) = 0$ dès que deux (au moins) des vecteurs $x_1, ...\,, x_n$ sont égaux.
\end{definition}
\begin{proposition}
Une forme $n$-linéaire alternée est antisymétrique: \\
Si $(y_1, ...\,, y_n)$ est obtenu à partir de $(x_1, ...\,, x_n)$ et échangeant $x_i$ et $x_j$ pour $i \neq j$, alors $f(y_1, ...\,, y_n) = f(x_1, ...\,, x_n)$
\end{proposition}
\noindent \uline{Changement de point de vue}: On peut considérer le déterminant comme un application
\[ \begin{cases}
K^n \times ... \times K^n \to K \text{ \quad (n fois) } \\
(c_1, ...\,, c_n) \mapsto \det(c_1, ...\,, c_n) = \det(c_1 \mid ... \mid c_n)
\end{cases}\]
\begin{theorem}
Le déterminant est une forme $n$-linéaire alternée sur $K^n$
\end{theorem}
\begin{corollaire}
Si $A \in M_n(K)$ n'est pas inversible, alors $\det(A) = 0$
\end{corollaire}
\begin{theorem}
Toute forme $n$-linéaire alternée sur $K^n$ est proportionnelle au déterminant.
\end{theorem}
\begin{corollaire}
\hfill
\begin{itemize}
\item Toute application $f: M_n(K) \to K$ "$n$-linéaire alternée par rapport aux colonnes" \\
s'écrit $\lambda \det$, où $\lambda = f(I_n)$
\item La même chose est vraie pour les application "$n$-linéaires alternées par rapport aux lignes".
\end{itemize}
\end{corollaire}
\begin{definition}
Étant donné un ev $E$ de dimension $n$ et $\mathcal{B}$ une base de $E$, on associe à toute famille $(v_1, ...\,, v_n)$ de vecteurs de $E$ le déterminant $\det_\mathcal{B} (v_1, ...\,, v_n) = \det \mat_\mathcal{B} (v_1, ...\,, v_n)$
\end{definition}

\pagebreak

\begin{corollaire}
Soit $E$ un ev de dimension $n$ et $\mathcal{B}$ une base de $E$
\begin{itemize}
\item Le déterminant
\[\textstyle{\det_\mathcal{B}} : \begin{cases}
E^n \to K \\
(v_1, ...\,, v_n) \mapsto \det_\mathcal{B} (v_1, ...\,, v_n)
\end{cases}\]
est une forme $n$-linéaire alternée sur $E$
\item Toute forme $n$-linéaire alternée sur $E$ est de la forme $\lambda \det_\mathcal{B}$ pour un certain $\lambda \in K$
\end{itemize}
\end{corollaire}

\subsection{Multiplicativité du déterminant}
\begin{theorem}
On a $\forall A, B \in M_n(K)$, $\det(AB) = \det(A) \det(B)$
\end{theorem}
\begin{corollaire}
\hfill
\begin{itemize}
\item On a $\forall A \in M_n(K)$, $\det(A) \neq 0 \implies A \in GL_n(K)$
\item Le déterminant induit un morphisme de groupes multiplicatifs \\
$\det: GL_n(K) \to K^*$
\end{itemize}
\end{corollaire}
\begin{definition}
On appelle \uline{groupe spécial linéaire} le noyau
\[ SL_n(K) = \ker(\det: GL_n(K) \to K^*) = \left\{ A \in M_n(K) \mid \det(A) = 1 \right\}\]
\end{definition}
\begin{corollaire}
Soit $E$ un espace vectoriel de dimension $n$ et $\mathcal{B}$ une base de $E$ \\
Soit $(v_1, ...\,, v_n)$ une famille de vecteurs de $E$ \\
Alors $\det_\mathcal{B}(v_1, ...\,, v_n) \neq 0 \iff (v_1, ...\,, v_n)$ base de $E$
\end{corollaire}

\subsection{Déterminant d'un endomorphisme}
\begin{proposition}
Deux matrices semblables ont le même déterminant.
\end{proposition}
\begin{definition}
Soit $E$ un ev de dimension $n$ et $f \in \mathcal{L}(E)$ \\
On définit le déterminant de $f$, noté $\det f$, comme le déterminant de $\mat_\mathcal{B}(f)$, pour une base $\mathcal{B}$ de $E$
\end{definition}
\begin{proposition}
Avec les mêmes notations, $\det f \neq 0$ si et seulement si $f$ est un automorphisme.
\end{proposition}
\begin{proposition}
Soit $E$ un espace vectoriel de dim $n$ muni d'une base $\mathcal{B}$, $v_1, ...\,, v_n \in E$ et $f \in \mathcal{L}(E)$ \\
Alors $\det_\mathcal{B}(f(v_1), ...\,, f(v_n)) = \det(f) \det_\mathcal{B}(v_1, ...\,, v_n)$
\end{proposition}

\section{Calculs}
\subsection{Opérations élémentaires}
\begin{proposition}
Soit $A \in M_n(K)$ \\
La matrice $A'$ obtenue à partir de $A$ en effectuant:
\begin{itemize}
\item Un échange $[L_i \leftrightarrow L_j]$ ou $[C_i \leftrightarrow C_j]$ vérifie $\det A' = -\det A$
\item Une dilatation $[L_i \leftarrow \lambda L_i]$ ou $[C_i \leftarrow \lambda C_i]$ vérifie $\det A' = \lambda \det A$
\item Une transvection $[L_i \leftarrow L_i + \lambda L_j]$ ou $[C_i \leftarrow C_i + \lambda C_j]$ vérifie $\det A' = \det A$
\end{itemize}
\end{proposition}

\pagebreak

\subsection{Développement par rapport à une ligne ou une colonne}
\begin{definition}
Soit $A \in M_n(K)$ et $(i, j) \in \llbracket , n \rrbracket^2$ \\
On définit:
\begin{itemize}
\item Le \uline{mineur} $(i, j)$: $\Delta_{i, j}$ qui est le déterminant de la matrice obtenue en supprimant \\
la $i$-ème ligne et la $j$-ème colonne de $A$
\item Le \uline{cofacteur} $(i, j)$ est $(-1)^{i + j} \Delta_{i, j}$
\end{itemize}
\end{definition}
\begin{theorem}
Soit $A \in M_n(K)$ \\
On a pour tout $i \in \llbracket 1, n \rrbracket$
\[ \det A = \sum_{j = 1}^n (-1)^{i + j} \Delta_{i, j} [A]_{i, j} \]
(développement par rapport à la $i$-ème ligne) \\
Et pour tout $j \in \llbracket 1, n \rrbracket$
\[ \det A = \sum_{i = 1}^n (-1)^{i + j} \Delta_{i, j} [A]_{i, j} \]
(développement par rapport à la $j$-ème colonne)
\end{theorem}
\begin{theorem}
Le déterminant d'une matrice triangulaire est le produit de ses coefficients diagonaux.
\end{theorem}
\begin{corollaire}
Une matrice triangulaire est inversible ssi aucun de ses coefficients diagonaux n'est nul.
\end{corollaire}
\begin{theorem}
On considère une matrice "triangulaire par blocs" 
\[M = \left(\begin{array}{c | c}
A & B \\
\hline
0 & C \\
\end{array}\right) \in M_{n + p}(K) \text{ où } \begin{cases}
A \in M_n(K) \\ C \in M_p(K) \\ B \in M_{np}(K)
\end{cases}\]
Alors $\det M = \det A \cdot \det C$
\end{theorem}

\subsection{Déterminant de Vandermonde}
\begin{theorem}
Soit $a_0, a_1, ...\,, a_{n - 1} \in K$ \\
Alors
\[ \begin{vmatrix}
1 & 1 & 1 & \cdots & 1 \\
a_0 & a_1 & a_2 & \cdots & a_{n - 1} \\
a_0^2 & a_1^2 & a_2^2 & \cdots & a_{n - 1}^2 \\
\vdots & \vdots & \vdots & & \vdots \\
a_0^{n - 1} & a_1^{n - 1} & a_2^{n - 1} & \cdots & a_{n - 1}^{n - 1}
\end{vmatrix} = \prod_{0 \leq i < j \leq n - 1} (a_j - a_i)\]
Ce déterminant est le \uline{déterminant de Vandermonde} $V(a_0, ...\,, a_{n - 1})$
\end{theorem}

\subsection{Comatrice}
\begin{definition}
Soit $A \in M_n(K)$ \\
La \uline{comatrice} de $A$ est la matrice
\[\com(A) = \left((-1)^{i + j} \Delta_{i, j}\right)_{1 \leq i, j \leq n}\]
des cofacteurs de $A$
\end{definition}
\begin{theorem}
Soit $A \in M_n(K)$ \\
On a $A \com(A)^T = \com(A)^T A = \det(A) I_n$
\end{theorem}
\begin{corollaire}
Si $A \in M_n(K)$, on a $A^{-1} = \frac{1}{\det A} \com(A)^T$
\end{corollaire}
\end{document}